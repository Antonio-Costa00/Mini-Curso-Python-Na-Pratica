{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7628/1704812088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Filo Artropoda - Família Culicidae',\n",
       "  'Farmácia Acadêmicos do curso de Farmácia em aula prática laboratorial na disciplina de Parasitologia realizaram observação e...',\n",
       "  'Out 1'],\n",
       " ['Projeto Saúde no Ponto',\n",
       "  'Educação Física O Centro Regional Universitário-UniPinhal e o curso de Educação Física, em parceria com o Supermercado Ponto Novo- SPN,...',\n",
       "  'Set 30'],\n",
       " ['Estudantes da ETEC de Espírito Santo do Pinhal visitam Campus Experimental Unipinhal',\n",
       "  'Engenharia Agronômica Na manhã do dia 27 de Setembro, estudantes da ETEC de Espírito Santo do Pinhal realizaram uma visita monitorada, no...',\n",
       "  'Set 29'],\n",
       " ['Escola de Ginástica - UniPinhal',\n",
       "  'Educação Física O Curso de Educação Física do UNIPINHAL realiza o Projeto de Extensão denominado “Escola de Ginástica”. O mesmo oferece a...',\n",
       "  'Set 29'],\n",
       " ['Prof.Dr. José Tarcísio F. Camargo desenvolve Projeto de pesquisa na área de Inteligência Artificial.',\n",
       "  'Engenharia de Computação \"O uso da inteligência artificial na observação de sentimentos humanos\". As redes sociais digitais constituem...',\n",
       "  'Set 29'],\n",
       " ['Setembro Amarelo',\n",
       "  'Educação Física O Curso de Educação Física do UniPinhal participou da campanha “Setembro Amarelo”, com o objetivo de prevenir e reduzir...',\n",
       "  'Set 28'],\n",
       " ['Centenário de Paulo Freire',\n",
       "  'História, Letras e Pedagogia Em 2021, Paulo Freire, o patrono da educação brasileira, teria completado 100 anos! Ele é o intelectual...',\n",
       "  'Set 24'],\n",
       " ['Engenharia Agronômica na escola',\n",
       "  'Engenharia Agronômica As estudantes Camili Oliveira e Maria Isabella, do nível 4 do curso de Engenharia Agronômica realizaram, na tarde...',\n",
       "  'Set 20'],\n",
       " ['Obtenção de insumos farmacêuticos ativos de origem vegetal',\n",
       "  'Farmácia Estudantes do curso de Farmácia em aula prática laboratorial na disciplina de Farmacognosia realizaram processos tecnológicos...',\n",
       "  'Set 20'],\n",
       " ['Dia do Profissional de Educação Física',\n",
       "  'Educação Física O curso de Educação Física promoveu a aula inaugural do semestre em comemoração ao Dia do Profissional de Educação...',\n",
       "  'Set 2'],\n",
       " ['Fermentação controlada em café arábica',\n",
       "  'Engenharia Agronômica O UniPinhal, com o apoio da  Terra Roxa consultoria, realizou nesta safra de 2020/2021, teste de pós-colheita   em...',\n",
       "  'Set 1'],\n",
       " ['O arquivo histórico pinhalense está a todo vapor!',\n",
       "  'História Você sabia que a UNIPINHAL está na vanguarda da preservação de documentos antigos? Estamos nos esforçando para digitalizar e...',\n",
       "  'Set 1'],\n",
       " ['Curso de História marca presença na Feira de Profissões no Cardeal Leme',\n",
       "  'História O curso de História da UNIPINHAL participou da feira de profissões da Escola Estadual Cardeal Leme! Em razão de excelente...',\n",
       "  'Set 1'],\n",
       " ['Curso de História da UNIPINHAL preservando nossa História!',\n",
       "  'História Curso de História e seus professores tem o privilégio de preservar e catalogar diversos acervos museológicos importantíssimos da...',\n",
       "  'Set 1'],\n",
       " ['Parceria da UNIPINHAL com a E. E. Cardeal Leme na 2ª Semana de Orientação Profissional.',\n",
       "  'UniPinhal A 2ª. Semana de Orientação Profissional da E. E. Cardeal Leme ocorreu nos dias 23, 24 e 25 de agosto de 2021, em parceria com a...',\n",
       "  'Ago 30'],\n",
       " ['Enfermagem UniPinhal promove ações no “Agosto Dourado”',\n",
       "  'Enfermagem O curso de Enfermagem UniPinhal promoveu para os alunos do 3◦ ano o Curso de “Promoção, proteção e apoio a amamentação”, com...',\n",
       "  'Ago 23'],\n",
       " ['Educação e Sociedade: Curso de Letras realiza parceria com cursinho popular Educafro.',\n",
       "  'Letras A discussão sobre teoria e prática é uma constante em todo processo de formação profissional. Como vincular todo aquele repertório...',\n",
       "  'Ago 5'],\n",
       " ['Aula Prática de Bioquímica.',\n",
       "  'Biomedicina Em aula prática, do curso de Biomedicina, na disciplina de Bioquímica, os estudantes puderam conhecer os laboratórios e todas...',\n",
       "  'Ago 4'],\n",
       " ['Laboratório Escola - LABESC',\n",
       "  'UniPinhal Sobre o Laboratório Escola (LabEsc) O Laboratório Escola (LabEsc) atenderá o município de Espírito Santo do Pinhal e região....',\n",
       "  'Jul 23'],\n",
       " ['Biomedicina UniPinhal: a serviço da Saúde.',\n",
       "  'Biomedicina A serviço da Saúde, futuros profissionais do curso de Biomedicina UniPinhal, sob todos os cuidados e seguindo os Protocolos...',\n",
       "  'Jul 6']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unipinhal():\n",
    "    url = \"https://www.sou.unipinhal.edu.br/noticias\"\n",
    "    website = requests.get(url)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    conteudo_website = website.content\n",
    "    website_analisado = BeautifulSoup(conteudo_website, 'html.parser')\n",
    "    noticias = website_analisado.find_all(\"div\", attrs={\"class\": \"_3tJ3x _1e-gz post-list-item-wrapper blog-post-homepage-description-font blog-post-homepage-description-color blog-post-homepage-description-fill _3RzkT\"})\n",
    "    noticias_completas = []\n",
    "    for noticia in noticias:\n",
    "        titulo = noticia.select('h2 div')[0].text\n",
    "        descricao = noticia.find('div', attrs={\"class\": \"_81XUh\"}).text\n",
    "        data = noticia.select('li span')[0].text\n",
    "        noticias_completas.append([titulo, descricao, data])\n",
    "    return noticias_completas\n",
    "unipinhal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Após a coleta dos dados vamos criar um **Dataframe** para armazenar esses dados em formato de tabela,e depois, exportar esses dados para uma tabela excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_dataframe(lista):\n",
    "    df = pd.DataFrame(lista, columns=['Título', 'descricao', 'data'])\n",
    "    print(df)\n",
    "    df.to_excel('noticiasUnipinhal.xlsx', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alibaba  resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_fornecedor_alibaba():\n",
    "    item = input('Digite o nome do produto: ')\n",
    "    numero_paginas = int(input('Digite o número de paginas: '))\n",
    "    url = f'https://www.alibaba.com/corporations/{item}.html?page=1'\n",
    "    # BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "    # ultima_pagina = BeautifulSoup(requests.get(url).content, 'html.parser').find_all('div', attrs={'class': 'ui2-pagination-pages'})\n",
    "    # ult_lista = [[ult.text] for ult in ultima_pagina]\n",
    "    # print(ult_lista)\n",
    "    lista_produtos = []\n",
    "    for i in range (1, numero_paginas + 1):\n",
    "        url = f'https://www.alibaba.com/corporations/{item}.html?page={i}'\n",
    "        print('pagina:', url)\n",
    "        website = requests.get(url)\n",
    "        if website.status_code != 200:\n",
    "            continue\n",
    "        website_content = website.content\n",
    "        website_parsed = BeautifulSoup(website_content, 'html.parser')\n",
    "        produtos = website_parsed.find_all(\"div\", attrs={\"class\": \"item-main\"})\n",
    "        for produto in produtos:\n",
    "            principais_produtos = produto.find(\"div\", attrs={\"class\": \"value ellipsis ph\"})\n",
    "            empresa = produto.find(\"a\", attrs={\"target\": \"_blank\"})\n",
    "            try:\n",
    "                lista_produtos.append([empresa.text, principais_produtos.text])\n",
    "            except Exception as e:\n",
    "                print(\"Algo errado. Erro:\", e)\n",
    "    pd.DataFrame(lista_produtos, columns = [\"Produto\", \"Preco\"]).to_excel('produtos.xlsx', index=False)\n",
    "busca_fornecedor_alibaba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unipinhal2():\n",
    "    noticias = website_parsed.find_all(\"span\", attrs={\"class\": \"_2PHJq public-DraftStyleDefault-ltr\"})\n",
    "    return [[noticia.text] for noticia in noticias]\n",
    "def unipinhal():\n",
    "    url = \"https://www.sou.unipinhal.edu.br/noticias\"\n",
    "    website = requests.get(url)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    conteudo_website = website.content\n",
    "    website_analisado = BeautifulSoup(conteudo_website, 'html.parser')\n",
    "    noticias = website_analisado.find_all(\"div\", attrs={\"class\": \"_3tJ3x _1e-gz post-list-item-wrapper blog-post-homepage-description-font blog-post-homepage-description-color blog-post-homepage-description-fill _3RzkT\"})\n",
    "    noticias_completas = []\n",
    "    for noticia in noticias:\n",
    "        titulo = noticia.select('h2 div')[0].text\n",
    "        data = noticia.select('li span')[0].text\n",
    "        noticias_completas.append([titulo, descricao, data])\n",
    "    return noticias_completas\n",
    "unipinhal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleta de dados de filmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coleta_de_dados_de_filmes1():\n",
    "    url = \"https://www.imdb.com/find?s=tt&q=acao&ref_=nv_sr_sm\"\n",
    "    website = requests.get(url)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    conteudo_website = website.content\n",
    "    website_analisado = BeautifulSoup(conteudo_website, 'html.parser')\n",
    "    informacoes = website_analisado.find_all(\"td\", attrs={\"class\": \"result_text\"})\n",
    "    informacoes_completas = []\n",
    "    for informacao in informacoes:\n",
    "        titulo = informacao.find('a').contents[0].text\n",
    "    #     descricao = informacao.find('div', attrs={\"class\": \"_81XUh\"}).text\n",
    "    #     data = informacao.select('li span')[0].text\n",
    "    #     informacoes_completas.append([titulo, descricao, data])\n",
    "        print(titulo)\n",
    "    # return informacoes_completas\n",
    "coleta_de_dados_de_filmes1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genero = input('Digite o genero do filme')\n",
    "url = f\"https://www.imdb.com/find?s=tt&q={genero}&ref_=nv_sr_sm\"\n",
    "website = requests.get(url)\n",
    "conteudo_website = website.content\n",
    "website_analisado = BeautifulSoup(conteudo_website, 'html.parser')\n",
    "titulos_filmes = [tag.find('a').contents[0] for tag in website_analisado.findAll('td', attrs={'class':'result_text'})]\n",
    "links_filmes = ['http://www.imdb.com' + tag.a['href'] for tag in website_analisado.findAll('td',  attrs={'class':'result_text'})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filme exemplo para testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_exemplo = 'https://www.imdb.com/title/tt10481868/?ref_=fn_tt_tt_4'\n",
    "request_exemplo = requests.get(link_exemplo)\n",
    "soup = BeautifulSoup(request_exemplo.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando o score dos filmes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = soup.find('span', attrs ={'class':\"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})\n",
    "print(score.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(soup):\n",
    "    score = soup.find('span', attrs ={'class':\"AggregateRatingButton__RatingScores-sc-1ll29m0-1 iTLWoV\"})\n",
    "    if score is None:\n",
    "        return None\n",
    "    else:\n",
    "        return float(score.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando numero de reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = soup.find('span', attrs ={'class':\"score\"})\n",
    "print(review.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qtdReviews(soup):\n",
    "    reviews = soup.find('span', attrs ={'class':\"score\"})\n",
    "    try:\n",
    "        for review in reviews:\n",
    "            if review.text.find('user') != -1:\n",
    "                qtd_r = review.text\n",
    "                print(review)\n",
    "                return int(qtd_r[:qtd_r.find(' user')])\n",
    "    except Exception:\n",
    "        return None\n",
    "get_qtdReviews(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando ano do filme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = soup.find('span', attrs ={'class':\"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "print(ano.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ano(soup):\n",
    "    ano = soup.find('span', attrs ={'class':\"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "    try:\n",
    "        return int(ano.text[0:4])\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coletando a sinopse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinopse = soup.find('span', attrs ={'class':\"GenresAndPlot__TextContainerBreakpointXS_TO_M-cum89p-0 dcFkRD\"})\n",
    "print(sinopse.text.replace('... Read all', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinopse(soup):\n",
    "    sinopse = soup.find('span', attrs ={'class':\"GenresAndPlot__TextContainerBreakpointXS_TO_M-cum89p-0 dcFkRD\"})\n",
    "    try:\n",
    "        return sinopse.text.replace('... Read all', ' ')\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código com todas funcoes reunidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_filmes = []\n",
    "for titulo, link, i in zip(titulos_filmes, links_filmes, range(20)):\n",
    "    dic = {'titulo': titulo, 'link': link}\n",
    "    con = requests.get(link)\n",
    "    soup = BeautifulSoup(con.content, \"html.parser\")\n",
    "    con.close()\n",
    "\n",
    "    dic['sinopse'] = get_sinopse(soup)\n",
    "    dic['score'] = get_score(soup)\n",
    "    dic['ano'] = get_ano(soup)\n",
    "    dic['qtd_reviews'] = get_qtdReviews(soup)\n",
    "    # replace('None', 'Não informado')\n",
    "    lista_filmes.append(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos fazer uma wordCloud com as palavras da sinopse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenar as palavras\n",
    "all_summary = ''.join(dic['sinopse'] for dic in lista_filmes)\n",
    "\n",
    "# lista de stopword\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"da\", \"meu\", \"em\", \"você\", \"de\", \"ao\", \"os\"])\n",
    "\n",
    "# gerar uma wordcloud\n",
    "wordcloud = WordCloud(stopwords=stopwords,\n",
    "                      background_color=\"black\",\n",
    "                      width=1600, height=800).generate(all_summary)\n",
    "\n",
    "# mostrar a imagem final\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.imshow(wordcloud, interpolation='bilinear')\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.imshow(wordcloud);\n",
    "wordcloud.to_file(\"airbnb_summary_wordcloud.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a producao de filmes do genero a cada ano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma lista dos anos em que cada filme foi produzido\n",
    "anos  = [dic['ano'] for dic in lista_filmes if dic['ano'] != None]\n",
    "anos = set(anos)\n",
    "print(anos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo intervalos de tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'1938 - 1979': 0, '1980 - 1984':0, '1985 - 1989':0, '1990 - 1994':0, '1995 - 1999':0,\n",
    "      '2000 - 2004':0, '2005 - 2009':0, '2010 - 2017':0, '2018 - 2021':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando contagem dentro dos intervalos de ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chave in dic:\n",
    "    for filme in lista_filmes:\n",
    "        anos = chave.split()\n",
    "        anos.remove('-')\n",
    "        if (\n",
    "            filme['ano'] != None\n",
    "            and filme['ano'] >= int(anos[0])\n",
    "            and filme['ano'] <= int(anos[1])\n",
    "        ):\n",
    "            dic[chave] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformando dados para **DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['intervalos_anos'] = dic.keys()\n",
    "df['freq'] = dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('intervalos_anos', 'freq', data=df, kind=\"bar\",palette=\"Greens\",size=6,aspect=2,legend_out=True);"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbd9425c94d3b7d880f607cce8957d6498c2afe1c2d4b83456ed58cfad26c53e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
