{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ **Aula 02: Parte 02 - Coletando e trabalhando com dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesta aula iremos estar aprendendo como coletar dados de alguns websites e como trabalhar com esses dados, e para isso, estaremos utilizando a biblioteca **Beautiful Soup** para realizar a **raspagem de dados**, a biblioteca **requests** para realizar as requisi√ß√µes e por √∫ltimo, utilizaremos a biblioteca **pandas** para trabalhar com os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. A Biblioteca requests** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A primeira coisa que precisamos fazer para realizar o web scrap √© baixar a p√°gina. Podemos baixar as p√°ginas utilizando a biblioteca requests do Python. <br>\n",
    "## A biblioteca requests far√° uma solicita√ß√£o GET ao servidor, que far√° o download dos conte√∫dos HTML da p√°gina solicitada para n√≥s. <br> \n",
    "## Existem v√°rios tipos de solicita√ß√£o diferentes que podemos realizar utilizando a biblioteca requests ‚Äì GET √© apenas um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. A Biblioteca BeautifulSoup** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/beautifulSoup.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depois de realizarmos uma requisicao bem sucedida da p√°gina que desejamos usando o requests, podemos utilizar a biblioteca BeautifulSoup para analisar o html da p√°gina e extrair o conte√∫do das tags que desejamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. A biblioteca Pandas** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pandas.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas** √© uma biblioteca de software criada para a linguagem Python para manipula√ß√£o e an√°lise de dados. <br>\n",
    "## Iremos utilizar-l√° para manipular os dados coletados durante a raspagem de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Instalando bibliotecas** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de importar as bibliotecas precisamos realizar a instalacao das mesmas. <br>\n",
    "## Para isso, iremos utilizar o gerenciador de pacotes do Python ***pip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Antonio Costa - Dev\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Antonio Costa - Dev\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Antonio Costa - Dev\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.21.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.3)\n",
      "Requirement already satisfied: six in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\antonio costa - dev\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Antonio Costa - Dev\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Importando pacotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5 Criando nosso primeiro programa** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Coletando dados do portal de not√≠cias da Unipinhal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de comecar a coleta, vamos verificar o site para coletar algumas informacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping_unipinhal():\n",
    "    url = 'https://www.sou.unipinhal.edu.br/noticias'\n",
    "    website = requests.get(url)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    # conteudo da requisicao\n",
    "    conteudo_website = website.content\n",
    "    # analise do resultado obtido\n",
    "    website_analisado = BeautifulSoup(conteudo_website, 'html.parser')\n",
    "    # Div contendo todos valores desejados\n",
    "    informacoes = website_analisado.find_all(\"div\", attrs= {\"class\":\"_3tJ3x _1e-gz post-list-item-wrapper blog-post-homepage-description-font blog-post-homepage-description-color blog-post-homepage-description-fill _3RzkT\"})\n",
    "    # criacao de lisdta vazia para ser preenchida com o tempo\n",
    "    informacoes_completas = []\n",
    "    for informacao in informacoes:\n",
    "        titulo = informacao.select('h2 div')[0]\n",
    "        descricao = informacao.find('div', attrs = {\"class\": \"_81XUh\"})\n",
    "        data = informacao.select('li span')[0]\n",
    "        informacoes_completas.append([titulo.text, descricao.text, data.text])\n",
    "    return informacoes_completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_informacoes = scrapping_unipinhal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lista_de_informacoes, columns = ['Titulo', 'Descricao', 'Data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('NoticiasUnipinhal.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Coletando e trabalhando com dados do website imbd.com** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Buscando filmes: Coletando dados de 200 filmes pelo genero escolhido**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A√ß√£o Mutante /title/tt0106215/\n",
      "A√ß√£o no Qu√™nia /title/tt0130350/\n",
      "A√ß√£o Direta /title/tt0368688/\n",
      "A√ß√£o e Rea√ß√£o /title/tt1261862/\n",
      "A√ß√£o Imediata /title/tt1182609/\n",
      "The Umbrella Academy /title/tt1312171/\n",
      "Acapulco /title/tt13567344/\n",
      "Boku no Hero Academia /title/tt5626028/\n",
      "Amizade de F√©rias /title/tt3626476/\n",
      "Gattaca, uma Experi√™ncia Gen√©tica /title/tt0119177/\n",
      "Macao /title/tt0044863/\n",
      "F√©rias Frustradas /title/tt1524930/\n",
      "Boku no Hero Academia: World Heroes Mission /title/tt13544716/\n",
      "Hotel Transilv√¢nia 3 - F√©rias Monstruosas /title/tt5220122/\n",
      "Loucademia de Pol√≠cia /title/tt0087928/\n",
      "A√ß√£o/Rea√ß√£o /title/tt1180168/\n",
      "Dupla A√ß√£o /title/tt1123534/\n",
      "C√¢mera... A√ß√£o! /title/tt6393794/\n",
      "A√ß√£o & Games /title/tt8822882/\n",
      "A√ß√£o Policial /title/tt7779038/\n",
      "F√©rias Frustradas /title/tt0085995/\n",
      "F√©rias Frustradas de Natal /title/tt0097958/\n",
      "Temos Vagas /title/tt0452702/\n",
      "As Espi√£s de Churchill /title/tt7698468/\n",
      "Academia de Vampiros: O Beijo das Sombras /title/tt1686821/\n",
      "Curacao /title/tt0106633/\n",
      "Dinheiro F√°cil: A S√©rie /title/tt10540276/\n",
      "Nausica√§ do Vale do Vento /title/tt0087544/\n",
      "Um Conto de Canterbury /title/tt0036695/\n",
      "Juventude Transviada /title/tt0048545/\n",
      "Mac - O Extraterrestre /title/tt0095560/\n",
      "Luz, C√¢mera, A√ß√£o /title/tt4060946/\n",
      "Bacao /title/tt4157484/\n",
      "Luz, Anima, A√ß√£o /title/tt3543026/\n",
      "Ithaca /title/tt3501590/\n",
      "A Case of Blue /title/tt7911348/\n",
      "Di√°rio Secreto de uma Garota de Programa /title/tt1000734/\n",
      "F√©rias Frustradas em Las Vegas /title/tt0120434/\n",
      "Cacao /title/tt12306806/\n",
      "Luz, Cama, A√ß√£o! /title/tt0252660/\n",
      "Greenhouse Academy /title/tt6076336/\n",
      "Macabre /title/tt0051885/\n",
      "Maca: Only Fans /title/tt13609634/\n",
      "Linha de A√ß√£o /title/tt1235522/\n",
      "Zack & Cody: G√™meos em A√ß√£o /title/tt0426371/\n",
      "Loucademia de Pol√≠cia 4: O Cidad√£o se Defende /title/tt0093756/\n",
      "Os Jovens Tit√£s em A√ß√£o! /title/tt2771780/\n",
      "A Castle for Christmas /title/tt13070602/\n",
      "LUZ, C√ÇMERA, A√á√ÉO! /title/tt9078218/\n",
      "F√©rias Frustradas II /title/tt0089670/\n",
      "Jorge Mautner - Kaos Em A√ß√£o /title/tt11744786/\n",
      "Poucas ondas, muita a√ß√£o /title/tt3399148/\n",
      "Sequ√™ncias de A√ß√£o /title/tt10750588/\n",
      "Luz, c√¢mera, a√ß√£o! /title/tt13092002/\n",
      "Luz, camera, a√ß√£o! /title/tt7692014/\n",
      "Oitenta Milh√µes em A√ß√£o /title/tt0592324/\n",
      "A√ß√£o de Despejo /title/tt13171834/\n",
      "Anjos em a√ß√£o V2 /title/tt7924696/\n",
      "Cozinheiros em A√ß√£o /title/tt5595828/\n",
      "Mulheres em A√ß√£o /title/tt6048056/\n",
      "Luz, C√¢meras e A√ß√£o /title/tt1876374/\n",
      "Na Cama /title/tt0474642/\n",
      "Kickboxing Academy /title/tt0119456/\n",
      "My Hero Academia: O Filme - Ascens√£o dos Her√≥is /title/tt11107074/\n",
      "Vampire Academy /title/tt14689620/\n",
      "Dance Academy /title/tt1551948/\n",
      "Dinheiro F√°cil /title/tt1291652/\n",
      "Prada: Candy /title/tt2808968/\n",
      "Movie Macabre /title/tt0262973/\n",
      "Bikini Model Academy /title/tt3208802/\n",
      "Macario /title/tt0054042/\n",
      "Um Brinde ao Natal /title/tt13055780/\n",
      "My Hero Academia: 2 Her√≥is /title/tt7745068/\n",
      "Hagure Yusha no Aestetica /title/tt2269368/\n",
      "The Misfit of Demon King Academy /title/tt12432936/\n",
      "F√©rias da Pesada /title/tt0089167/\n",
      "Pup Academy /title/tt10302548/\n",
      "Macabre /title/tt1447791/\n",
      "Loucademia de Pol√≠cia 3: De Volta ao Treinamento /title/tt0091777/\n",
      "Macabro /title/tt0080764/\n",
      "Aluga-se um Para√≠so /title/tt14691382/\n",
      "Loucademia de Pol√≠cia 2: A Primeira Miss√£o /title/tt0089822/\n",
      "Acting for a Cause /title/tt12014962/\n",
      "The Helpers /title/tt1854582/\n",
      "Elvira's Movie Macabre /title/tt1721556/\n",
      "Jersey Shore: Family Vacation /title/tt7686456/\n",
      "Rebeldes da Academia /title/tt0081695/\n",
      "Um Caso de Amor /title/tt1817081/\n",
      "Skylanders Academy /title/tt5916218/\n",
      "Ilha dos Desafios /title/tt1173427/\n",
      "Unsolved /title/tt6233618/\n",
      "Looney Tunes: De Volta √† A√ß√£o /title/tt0318155/\n",
      "Cacao /title/tt1574542/\n",
      "El Cacao /title/tt5279896/\n",
      "√Å La Carte /title/tt15683952/\n",
      "F√©rias da Fam√≠lia Johnson /title/tt0359517/\n",
      "F√©rias Permanentes /title/tt0084488/\n",
      "A Cam Life /title/tt5657764/\n",
      "Zac and Mia /title/tt7487358/\n",
      "O Seresteiro de Acapulco /title/tt0057083/\n",
      "Loucademia de Pol√≠cia 7: Miss√£o Moscou /title/tt0110857/\n",
      "La vacanza /title/tt0065161/\n",
      "Loucademia de Pol√≠cia 5: Miss√£o Miami Beach /title/tt0095882/\n",
      "Cuidado, Espi√£o Brasileiro em A√ß√£o /title/tt0336220/\n",
      "A Gaiola das Loucas /title/tt0077288/\n",
      "Little Witch Academia /title/tt6352180/\n",
      "Ori no naka no y√¥sei /title/tt0226267/\n",
      "Sedu√ß√£o /title/tt0071286/\n",
      "Space Academy /title/tt0075585/\n",
      "Morte S√∫bita /title/tt2554946/\n",
      "MacArthur, O General Rebelde /title/tt0076342/\n",
      "A Dama Enjaulada /title/tt0058283/\n",
      "Luz, C√¢mera, A√ß√£o: Parte 1 /title/tt9707822/\n",
      "Luz, C√¢mera, A√ß√£o: Parte 2 /title/tt9707826/\n",
      "La caza. Monteperdido /title/tt8787372/\n",
      "Aimy in a Cage /title/tt3550078/\n",
      "Loucademia de Pol√≠cia Feminina /title/tt0096379/\n",
      "Opera√ß√£o Acapulco /title/tt0105930/\n",
      "Loucademia de Pol√≠cia 6: Cidade em Estado de S√≠tio /title/tt0098105/\n",
      "Vampire Academy: the Officially Unofficial Fan Series /title/tt5721182/\n",
      "No Vacancy /title/tt0171576/\n",
      "Monica O My Darling /title/tt15128068/\n",
      "Le sorelle Macaluso /title/tt12789110/\n",
      "Gossip Girl: Acapulco /title/tt2958762/\n",
      "Temos Vagas 2: A Primeira Di√°ria /title/tt1204979/\n",
      "Acapulco Shore /title/tt5459372/\n",
      "Hitler - Eine Karriere /title/tt0191182/\n",
      "The Dana Carvey Show /title/tt0115148/\n",
      "Vita da Carlo /title/tt14691760/\n",
      "Akadimia Platonos /title/tt1334313/\n",
      "Macao /title/tt0222173/\n",
      "Um gato no C√©rebro /title/tt0099637/\n",
      "Seikoku no Dragonar /title/tt3432596/\n",
      "Dance Academy: o Filme /title/tt5834660/\n",
      "Regal Academy /title/tt5958514/\n",
      "Os Jovens Tit√£s em A√ß√£o! Vs. Os Jovens Tit√£s /title/tt10548944/\n",
      "Miss Marple: A Caribbean Mystery /title/tt0097015/\n",
      "My Hero Academia: All Might Rising /title/tt11589858/\n",
      "Macao /title/tt12855218/\n",
      "James Acaster: Repertoire /title/tt7818686/\n",
      "Acasa, My Home /title/tt11364376/\n",
      "Villa Caprice /title/tt10019108/\n",
      "A Rebelde /title/tt0065516/\n",
      "Scooby-Doo! Abracadabra-Doo /title/tt1599351/\n",
      "Um Gato em Paris /title/tt1673702/\n",
      "Jong chak yeok /title/tt13995564/\n",
      "Cacao /title/tt4664538/\n",
      "Macao /title/tt1685155/\n",
      "Macao /title/tt5283786/\n",
      "Cacao /title/tt9402804/\n",
      "Macao /title/tt1661242/\n",
      "Bad Kids of Crestview Academy /title/tt3349578/\n",
      "As F√©rias de Papai /title/tt0056255/\n",
      "Hotel Hell Vacation /title/tt1600409/\n",
      "Fique Comigo /title/tt4357368/\n",
      "Acapulco H.E.A.T. /title/tt0180339/\n",
      "Arsenal Military Academy /title/tt11024384/\n",
      "Acacias 38 /title/tt4546290/\n",
      "Morangos com A√ß√∫car /title/tt0391666/\n",
      "Desenhos Incr√≠veis - O Show /title/tt0181266/\n",
      "O Tesouro Maldito /title/tt0077118/\n",
      "Police Academy: The Series /title/tt0126168/\n",
      "Anacaona /title/tt11155272/\n",
      "Confiss√µes de um Apostador /title/tt0299535/\n",
      "Os Jovens Tit√£s em A√ß√£o! Nos Cinemas /title/tt7424200/\n",
      "La Casa De Mama Icha /title/tt15385952/\n",
      "Loucademia de Mulheres 3 /title/tt0103204/\n",
      "Tiras da Pesada /title/tt0129532/\n",
      "Mancao /title/tt1332109/\n",
      "Boku no h√Ær√¥ akademia: Training of the Dead /title/tt6848466/\n",
      "Doja Cat Feat. SZA: Kiss Me More /title/tt14424444/\n",
      "Academia de Ver√£o /title/tt0111248/\n",
      "Comandos em A√ß√£o /title/tt0086719/\n",
      "La cabina /title/tt0065513/\n",
      "Manson Family Vacation /title/tt3275216/\n",
      "Witches of Amityville Academy /title/tt10863072/\n",
      "Project Ithaca /title/tt6490930/\n",
      "A Promiss√≥ria /title/tt0052668/\n",
      "WITS Academy /title/tt5103536/\n",
      "F√©rias em Fam√≠lia com Chucky e Tiffany /title/tt9419584/\n",
      "Massacre Academy /title/tt11844456/\n",
      "Loucos por Mouser /title/tt2481554/\n",
      "Abracadabra /title/tt5187886/\n",
      "Man with a Camera /title/tt0051293/\n",
      "Camera Caf√© /title/tt0831821/\n",
      "Comendo Pelas Bordas 4: Acampamento de Atores /title/tt1833845/\n",
      "Cola cao /title/tt7320510/\n",
      "Curacao /title/tt1687770/\n",
      "Devacao /title/tt6419732/\n",
      "Curacao /title/tt1331030/\n",
      "Curacao /title/tt12758202/\n",
      "Curacao /title/tt10924994/\n",
      "Curacao /title/tt5730956/\n",
      "Curacao /title/tt6802170/\n",
      "Curacao /title/tt2357721/\n",
      "Curacao /title/tt2124211/\n",
      "Stripper Academy /title/tt1018790/\n",
      "Abracashoes /title/tt12381212/\n",
      "El arracadas /title/tt0205750/\n",
      "Vikend sa caletom /title/tt13899680/\n"
     ]
    }
   ],
   "source": [
    "def busca_filmes(genero):\n",
    "    # url dos filmes a serem buscados\n",
    "    url = f'https://www.imdb.com/find?s=tt&q={genero}&ref_=nv_sr_sm'\n",
    "    website = requests.get(url)\n",
    "    # condicao: se o codigo for diferente de 200 faca com que a funcao nao retorne nada (parar a funcao)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    #seguimento padrao (coletando conteudo do website)\n",
    "    cont_web = website.content\n",
    "    #seguimento padrao (analisando o conteudo do website)\n",
    "    website_analisado = BeautifulSoup(cont_web, 'html.parser')\n",
    "    #titulo, link do filme\n",
    "    informacoes = website_analisado.findAll(\"td\", attrs = {\"class\": \"result_text\"})\n",
    "    informacoes_filmes = []\n",
    "    for informacao in informacoes:\n",
    "        #coletando o a da div (a div possui apenas uma tag a, logo, buscando por ela nesse ionetrvalo conseguimos extrair o texto dela.)\n",
    "        titulo = informacao.find('a').text\n",
    "        # coletando link\n",
    "        link_filme = informacao.find('a')['href']\n",
    "        #Como estamos fazendo o append com mais de um item, 'e necessario criar uma lista dentro do append, por isso os colchetes\n",
    "        informacoes_filmes.append([titulo, link_filme])\n",
    "        print(titulo, link_filme)\n",
    "\n",
    "filme = input(\"Digite um genero de filme\")\n",
    "busca_filmes(filme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Coletar ano de producao e score de todos os 200 filmes ja coletados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para isso, vamos utilizar um filme exemplo para coletar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_exemplo = f\"https://www.imdb.com/title/tt0130350/?ref_=fn_tt_tt_2\"\n",
    "request_exemplo = requests.get(link_exemplo)\n",
    "analise = BeautifulSoup(request_exemplo.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Coletando o ano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = analise.find(\"span\", attrs = {\"class\": \"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "print(ano.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao que retorna o ano de todos os filmes, de acordo com o parametro *analise_site*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ano(analise_site):\n",
    "    ano =  analise_site.find(\"span\", attrs = {\"class\": \"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "    try:\n",
    "        return (int(ano.text))\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Coletando score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = analise.find(\"span\", attrs = {\"class\": \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})\n",
    "print(score.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao que retorna o score de todos os filmes, de acordo com o parametro *analise_site*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(analise_site):\n",
    "    score = analise_site.find(\"span\", attrs = {\"class\": \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})\n",
    "    if score is None:\n",
    "        return None\n",
    "    return float(score.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reunindo as funcoes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'titulo': 'Rogue, o Assassino', 'link': 'https://www.imdb.com/title/tt0499556/', 'score': 6.2, 'ano': 2007}, {'titulo': 'Guerra', 'link': 'https://www.imdb.com/title/tt7430722/', 'score': 6.5, 'ano': 2019}, {'titulo': 'Guerra', 'link': 'https://www.imdb.com/title/tt3830162/', 'score': 7.1, 'ano': 2015}, {'titulo': 'Guerra dos Tronos', 'link': 'https://www.imdb.com/title/tt0944947/', 'score': 9.2, 'ano': None}, {'titulo': 'Guerra nas Estrelas', 'link': 'https://www.imdb.com/title/tt0076759/', 'score': 8.6, 'ano': 1977}, {'titulo': 'O Imp√©rio Contra-Ataca', 'link': 'https://www.imdb.com/title/tt0080684/', 'score': 8.7, 'ano': 1980}, {'titulo': 'Guerra Mundial Z', 'link': 'https://www.imdb.com/title/tt0816711/', 'score': 7.0, 'ano': 2013}, {'titulo': 'Guerra dos Mundos', 'link': 'https://www.imdb.com/title/tt0407304/', 'score': 6.5, 'ano': 2005}, {'titulo': 'Homeland', 'link': 'https://www.imdb.com/title/tt1796960/', 'score': 8.3, 'ano': None}, {'titulo': 'Irm√£os de Guerra', 'link': 'https://www.imdb.com/title/tt0185906/', 'score': 9.4, 'ano': 2001}]\n"
     ]
    }
   ],
   "source": [
    "def get_ano(analise_site):\n",
    "    ano =  analise_site.find(\"span\", attrs = {\"class\": \"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "    try:\n",
    "        return (int(ano.text))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def get_score(analise_site):\n",
    "    score = analise_site.find(\"span\", attrs = {\"class\": \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})\n",
    "    if score is None:\n",
    "        return None\n",
    "    return float(score.text)\n",
    "\n",
    "def buscador_filmes(genero, numero_filmes):\n",
    "    url = f'https://www.imdb.com/find?s=tt&q={genero}&ref_=nv_sr_sm'\n",
    "    website = requests.get(url)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    cont_web = website.content\n",
    "    website_analisado = BeautifulSoup(cont_web, 'html.parser')\n",
    "    #titulo, link do filme\n",
    "    informacoes_filmes = website_analisado.findAll(\"td\", attrs = {\"class\": \"result_text\"})\n",
    "    titulos_filmes = []\n",
    "    links_completos = []\n",
    "\n",
    "    # Primeiro for: Coletar titulos e links dos filmes\n",
    "    for informacao_filme, i in zip(informacoes_filmes, range(numero_filmes)):\n",
    "        titulo = informacao_filme.find('a').text\n",
    "        link_padrao = \"https://www.imdb.com\"\n",
    "        link_filme = informacao_filme.find('a')['href']\n",
    "        link_completo = link_padrao + link_filme\n",
    "        titulos_filmes.append(titulo)\n",
    "        links_completos.append(link_completo)\n",
    "\n",
    "    lista_filmes = []\n",
    "    # Segundo for: com os links coletados fazer uma iteracao em cada um e coletar as informacoes das funcoes get_score() e get_ano())\n",
    "    for titulo, link_completo in zip(titulos_filmes, links_completos):\n",
    "        dic = {'titulo': titulo, 'link': link_completo}\n",
    "        req = requests.get(link_completo)\n",
    "        analise = BeautifulSoup(req.content, 'html.parser')\n",
    "        req.close()\n",
    "\n",
    "        dic['score'] = get_score(analise)\n",
    "        dic['ano'] = get_ano(analise)\n",
    "        lista_filmes.append(dic)\n",
    "\n",
    "    print(lista_filmes)\n",
    "genero_filme = input(\"Digite um genero de filme \")\n",
    "qtt_filmes = int(input(\"Quantos filmes voce deseja coletar? \"))\n",
    "\n",
    "buscador_filmes(genero_filme, qtt_filmes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ab92b8776bd6db82bb5c0767e875b4073e50e02af11cd0b3337cf610213e0ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
