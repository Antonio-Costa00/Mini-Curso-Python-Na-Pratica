{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ **Aula 02: Parte 02 - Coletando e trabalhando com dados**\n",
    "## Nesta aula iremos estar aprendendo como coletar dados de alguns websites e como trabalhar com esses dados, e para isso, estaremos utilizando a biblioteca **Beautiful Soup** para realizar a **raspagem de dados**, a biblioteca **requests**, para realizar as requisi√ß√µes e por ultimo, utilizaremos a biblioteca **pandas**, para trabalhar com os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. A Biblioteca requests** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A primeira coisa que precisamos fazer para realizar o web scrap √© baixar a p√°gina. Podemos baixar as p√°ginas utilizando a biblioteca requests do Python. <br>\n",
    "## A biblioteca requests far√° uma solicita√ß√£o GET ao servidor, que far√° o download dos conte√∫dos HTML da p√°gina solicitada para n√≥s. <br> \n",
    "## Existem v√°rios tipos de solicita√ß√£o diferentes que podemos realizar utilizando a biblioteca requests ‚Äì GET √© apenas um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. A Biblioteca BeautifulSoup** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/beautifulSoup.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depois de realizarmos uma requisicao bem sucedida da p√°gina que desejamos usando o requests, podemos utilizar a biblioteca BeautifulSoup para analisar o html da p√°gina e extrair o conte√∫do das tags que desejamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. A biblioteca Pandas** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/pandas.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **pandas** √© uma biblioteca de software criada para a linguagem Python para manipula√ß√£o e an√°lise de dados. <br>\n",
    "## Iremos utilizar-l√° para manipular os dados coletados durante a raspagem de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Instalando bibliotecas** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de importar as bibliotecas precisamos realizar a instalacao das mesmas. <br>\n",
    "## Para isso, iremos utilizar o gerenciador de pacotes do Python ***pip***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Importando pacotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5 Criando nosso primeiro programa** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Coletando dados do portal de not√≠cias da Unipinhal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de comecar a coleta, vamos verificar o site para coletar algumas informacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping_unipinhal():\n",
    "    url = 'https://www.sou.unipinhal.edu.br/noticias'\n",
    "    website = requests.get(url)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    # conteudo da requisicao\n",
    "    conteudo_website = website.content\n",
    "    # analise do resultado obtido\n",
    "    website_analisado = BeautifulSoup(conteudo_website, 'html.parser')\n",
    "    # Div contendo todos valores desejados\n",
    "    informacoes = website_analisado.find_all(\"div\", attrs= {\"class\":\"_3tJ3x _1e-gz post-list-item-wrapper blog-post-homepage-description-font blog-post-homepage-description-color blog-post-homepage-description-fill _3RzkT\"})\n",
    "    # criacao de lisdta vazia para ser preenchida com o tempo\n",
    "    informacoes_completas = []\n",
    "    for informacao in informacoes:\n",
    "        titulo = informacao.select('h2 div')[0]\n",
    "        descricao = informacao.find('div', attrs = {\"class\": \"_81XUh\"})\n",
    "        data = informacao.select('li span')[0]\n",
    "        informacoes_completas.append([titulo.text, descricao.text, data.text])\n",
    "    return informacoes_completas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_de_informacoes = scrapping_unipinhal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lista_de_informacoes, columns = ['Titulo', 'Descricao', 'Data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('NoticiasUnipinhal.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Coletando e trabalhando com dados do website imbd.com** ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Buscando filmes: Coletando dados de 200 filmes pelo genero escolhido**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_filmes(genero):\n",
    "    # url dos filmes a serem buscados\n",
    "    url = f'https://www.imdb.com/find?s=tt&q={genero}&ref_=nv_sr_sm'\n",
    "    website = requests.get(url)\n",
    "    # condicao: se o codigo for diferente de 200 faca com que a funcao nao retorne nada (parar a funcao)\n",
    "    if website.status_code != 200:\n",
    "        return None\n",
    "    #seguimento padrao (coletando conteudo do website)\n",
    "    cont_web = website.content\n",
    "    #seguimento padrao (analisando o conteudo do website)\n",
    "    website_analisado = BeautifulSoup(cont_web, 'html.parser')\n",
    "    #titulo, link do filme, ano do filme\n",
    "    informacoes = website_analisado.findAll(\"td\", attrs = {\"class\": \"result_text\"})\n",
    "    informacoes_filmes = []\n",
    "    for informacao in informacoes:\n",
    "        #coletando o a da div (a div possui apenas uma tag a, logo, buscando por ela nesse ionetrvalo conseguimos extrair o texto dela.)\n",
    "        titulo = informacao.find('a').text\n",
    "        # coletando link\n",
    "        link_filme = informacao.find('a')['href']\n",
    "        #Como estamos fazendo o append com mais de um item, 'e necessario criar uma lista dentro do append, por isso os colchetes\n",
    "        informacoes_filmes.append([titulo, link_filme])\n",
    "        print(titulo, link_filme)\n",
    "\n",
    "filme = input(\"Digite um genero de filme\")\n",
    "busca_filmes(filme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Coletar ano de producao e score de todos os 200 filmes ja coletados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para isso, vamos utilizar um filme exemplo para coletar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_exemplo = f\"https://www.imdb.com/title/tt0130350/?ref_=fn_tt_tt_2\"\n",
    "request_exemplo = requests.get(link_exemplo)\n",
    "analise = BeautifulSoup(request_exemplo.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Coletando o ano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = analise.find(\"span\", attrs = {\"class\": \"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "print(ano.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao que retorna o ano de todos os filmes, de acordo com o parametro *analise_site*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ano(analise_site):\n",
    "    ano =  analise_site.find(\"span\", attrs = {\"class\": \"TitleBlockMetaData__ListItemText-sc-12ein40-2 jedhex\"})\n",
    "    try:\n",
    "        return (int(ano.text))\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Coletando score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = analise.find(\"span\", attrs = {\"class\": \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})\n",
    "print(score.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcao que retorna o score de todos os filmes, de acordo com o parametro *analise_site*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(analise_site):\n",
    "    score = analise_site.find(\"span\", attrs = {\"class\": \"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\"})\n",
    "    if score is None:\n",
    "        return None\n",
    "    return float(score.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma funcao geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genero = input(\"Digite o genero do filme: \")\n",
    "url = f'https://www.imdb.com/find?s=tt&q={genero}&ref_=nv_sr_sm'\n",
    "website = requests.get(url)\n",
    "if website.status_code != 200:\n",
    "    print('codigo diferente de 200')\n",
    "cont_web = website.content\n",
    "website_analisado = BeautifulSoup(cont_web, 'html.parser')\n",
    "#titulo, link do filme\n",
    "informacoes = website_analisado.findAll(\"td\", attrs = {\"class\": \"result_text\"})\n",
    "titulos_filmes = []\n",
    "links_filmes = []\n",
    "# Primeiro for: Coletar titulos e links dos filmes\n",
    "for informacao in informacoes:\n",
    "    titulo = informacao.find('a').text\n",
    "    link_filme = \"https://www.imdb.com\" + informacao.find('a')['href']\n",
    "    titulos_filmes.append(titulo)\n",
    "    links_filmes.append(link_filme)\n",
    "print(titulos_filmes)\n",
    "lista_filmes = []\n",
    "# Segundo for: com os links coletados fazer uma iteracao em cada um e coletar as informacoes das funcoes get_score() e get_ano())\n",
    "for titulo, link, i in zip(titulos_filmes, links_filmes, range(20)):\n",
    "    dic = {'titulo': titulo, 'link': link}\n",
    "    req = requests.get(link)\n",
    "    analise = BeautifulSoup(req.content, 'html.parser')\n",
    "    req.close()\n",
    "\n",
    "    dic['score'] = get_score(analise)\n",
    "    dic['ano'] = get_ano(analise)\n",
    "    lista_filmes.append(dic)\n",
    "\n",
    "print(lista_filmes)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ab92b8776bd6db82bb5c0767e875b4073e50e02af11cd0b3337cf610213e0ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
